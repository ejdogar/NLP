{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aaljpVvlzsG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/reviews.txt', 'r') as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/labels.txt', 'r') as f:\n",
        "  labels = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews[:1000])\n",
        "print()\n",
        "print(labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcl92pDcmrqc",
        "outputId": "3a6be466-e865-4d4b-d3b3-d0c86b16eb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
            "\n",
            "positive\n",
            "n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "all_words = all_text.split()\n",
        "\n"
      ],
      "metadata": {
        "id": "ml5ac4WRm3Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label =='positive' else 0 for label in labels_split])"
      ],
      "metadata": {
        "id": "WIROWcWyn_eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "review_lens = Counter([len(x.split()) for x in reviews_split])\n",
        "print(\"Zero lenght : {}\".format(review_lens[0]))\n",
        "print(\"Max lenght : {}\".format(max(review_lens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPCZzdN0o6b1",
        "outputId": "b19f2101-d3db-465f-cd41-3d8f852346d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero lenght : 1\n",
            "Max lenght : 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_zero_idx = [ii for ii, review in enumerate(reviews_split) if len(review.split()) != 0]\n",
        "\n",
        "reviews_split = [reviews_split[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])"
      ],
      "metadata": {
        "id": "9q6P-fi2qGem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "embed_lookup = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/word2vec_model/GoogleNews-vectors-negative300-SLIM.bin',\n",
        "                                                 binary=True)"
      ],
      "metadata": {
        "id": "5l3wJErLqJWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_words =[]\n",
        "for index, word in enumerate(embed_lookup.index_to_key):\n",
        "  pretrained_words.append(word)"
      ],
      "metadata": {
        "id": "rgCsfsoWs0oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_all_reviews(embed_lookup, reviews_split):\n",
        "    reviews_words = [review.split() for review in reviews_split]\n",
        "\n",
        "    tokenized_reviews = []\n",
        "    for review in reviews_words:\n",
        "        ints = []\n",
        "        for word in review:\n",
        "            try:\n",
        "                idx = embed_lookup.key_to_index[word]\n",
        "            except:\n",
        "                idx = 0\n",
        "            ints.append(idx)\n",
        "        tokenized_reviews.append(ints)\n",
        "\n",
        "    return tokenized_reviews\n",
        "\n"
      ],
      "metadata": {
        "id": "P-LWU2iZuQok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = tokenize_all_reviews(embed_lookup, reviews_split)\n",
        "print(tokenized_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlYA5GGwdKO",
        "outputId": "9ed719f7-c941-4c40-c986-075fcec3288e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 137, 3, 0, 11620, 3799, 13, 1215, 10, 9, 194, 54, 12, 73, 61, 685, 41, 183, 243, 129, 12, 1663, 119, 72, 0, 9, 2989, 7334, 242, 159, 0, 453, 2, 0, 137, 1239, 19951, 3, 141, 1980, 0, 1898, 55, 3, 1663, 9, 11124, 0, 3857, 6663, 9, 20401, 295, 28, 45, 148, 157, 102, 27, 15452, 1663, 30714, 9, 65172, 0, 9, 844, 737, 47, 6585, 159, 0, 9, 668, 4365, 1003, 0, 27, 295, 56, 4365, 622, 9, 3832, 0, 43, 0, 897, 3187, 907, 0, 5396, 113, 9, 183, 4365, 1009, 3165, 10, 137, 0, 3288, 296, 10314, 4365, 6638, 213, 0, 8810, 40, 0, 116, 1663, 897, 2059, 0, 0, 137, 4365, 830, 2, 124, 2216, 0, 119, 782, 144, 2, 0, 137, 3, 330, 23046, 78, 0, 16915, 2, 13, 85275, 7451]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(tokenized_reviews, seq_length):\n",
        "    features = np.zeros((len(tokenized_reviews), seq_length), dtype=int)\n",
        "    for i, row in enumerate(tokenized_reviews):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "5i2DOZfzw6_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequecne_length = 200\n",
        "features = pad_features(tokenized_reviews, seq_length=sequecne_length)\n",
        "\n",
        "print(features[:10,:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLSjePNNxWoK",
        "outputId": "d60ccb6f-b32c-42a4-a989-d0bdd77261b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [ 16483     26      0     12 106210      0   1698     22     37     24\n",
            "     432      1     72     30    275      0    303      0    162    126]\n",
            " [  1935   1326     12      0   1403     60   3921   2019      3   4809\n",
            "      36      6   3172   7184    129   7951      0   2180   6098 166268]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [    56   4365      8    270    119    756    247    159    381      0\n",
            "       9   2669      0    148  21621     13      8     40      0    124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8 #80% Training data      20% Test Data\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lfr56MMRx4HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "QZcbcirl2K-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UaGbHnE20IP",
        "outputId": "1b872559-e4f1-4cfe-b866-b1054e434bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentCNN(nn.Module):\n",
        "    def __init__(self, embed_model, vocab_size, output_size, embedding_dim,\n",
        "                 num_filters=100, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
        "        super(SentimentCNN, self).__init__()\n",
        "\n",
        "        self.num_filters = num_filters\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.embedding.weight = nn.Parameter(torch.from_numpy(embed_model.vectors)) # all vectors\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            self.embedding.requires_grad = False\n",
        "\n",
        "        self.convs_1d = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (k, embedding_dim), padding=(k-2,0))\n",
        "            for k in kernel_sizes])\n",
        "\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.sig = nn.Sigmoid()\n"
      ],
      "metadata": {
        "id": "-JzKNrYe3H9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}