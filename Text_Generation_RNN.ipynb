{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejdogar/NLP/blob/main/Text_Generation_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import keras"
      ],
      "metadata": {
        "id": "ddOoR2n_tbcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pN3SjHAwwO6f"
      },
      "outputs": [],
      "source": [
        "docs = [\"Hey how are you\",\n",
        "        \"Hey whats up\",\n",
        "        \"Pakistan lost the match\",\n",
        "        \"it is raining\",\n",
        "        \"Charles Leclerc will be the F1 champion of 2024\",\n",
        "        \"Ronaldo is the best football player\",\n",
        "        \"Schumacher was the best driver ever\",\n",
        "        \"Lewis Hamilton is a cheat\",\n",
        "        \"Sebastian Vettel is struggling\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "YwzJ82CHovWI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "Cp03Z5QEwkXo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)"
      ],
      "metadata": {
        "id": "HMrkx3QCo8XM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3xrCVbBuBV4",
        "outputId": "d20e6a54-b5f1-450b-9d0f-f8857ef8663f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 5, 6, 7], [3, 8, 9], [10, 11, 1, 12], [13, 2, 14], [15, 16, 17, 18, 1, 19, 20, 21, 22], [23, 2, 1, 4, 24, 25], [26, 27, 1, 4, 28, 29], [30, 31, 2, 32, 33], [34, 35, 2, 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2int = tokenizer.word_index\n",
        "print(word2int)\n",
        "vocab_size = len(word2int)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZZU7pxvpMBU",
        "outputId": "0ba211a6-a084-47e0-a890-b3ec5ed0018e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'is': 2, 'hey': 3, 'best': 4, 'how': 5, 'are': 6, 'you': 7, 'whats': 8, 'up': 9, 'pakistan': 10, 'lost': 11, 'match': 12, 'it': 13, 'raining': 14, 'charles': 15, 'leclerc': 16, 'will': 17, 'be': 18, 'f1': 19, 'champion': 20, 'of': 21, '2024': 22, 'ronaldo': 23, 'football': 24, 'player': 25, 'schumacher': 26, 'was': 27, 'driver': 28, 'ever': 29, 'lewis': 30, 'hamilton': 31, 'a': 32, 'cheat': 33, 'sebastian': 34, 'vettel': 35, 'struggling': 36}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int2word = {idx+1: word for idx, word in enumerate(word2int)}"
      ],
      "metadata": {
        "id": "R6VCKKAbqeFr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "sequences = pad_sequences(sequences, padding=\"post\")\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53QDxLVaq9KI",
        "outputId": "dad83c0c-90de-4871-82b6-f5032c8ebbf6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  5,  6,  7,  0,  0,  0,  0,  0],\n",
              "       [ 3,  8,  9,  0,  0,  0,  0,  0,  0],\n",
              "       [10, 11,  1, 12,  0,  0,  0,  0,  0],\n",
              "       [13,  2, 14,  0,  0,  0,  0,  0,  0],\n",
              "       [15, 16, 17, 18,  1, 19, 20, 21, 22],\n",
              "       [23,  2,  1,  4, 24, 25,  0,  0,  0],\n",
              "       [26, 27,  1,  4, 28, 29,  0,  0,  0],\n",
              "       [30, 31,  2, 32, 33,  0,  0,  0,  0],\n",
              "       [34, 35,  2, 36,  0,  0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlength = len(sequences[0])\n",
        "maxlength"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldIIfzbrr31n",
        "outputId": "a759f8fe-b796-4252-eaa0-1823d3c84f43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = []\n",
        "target_seq = []\n",
        "for i in range(len(sequences)):\n",
        "  input_seq.append(sequences[i][:-1])\n",
        "  target_seq.append(sequences[i][1:])\n",
        "\n",
        "print(f\"{input_seq[0]=}\")\n",
        "print(f\"{target_seq[0]=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNVe0ZHGsEFN",
        "outputId": "14a8055e-5a71-4291-eb0e-f8105b8c8628"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_seq[0]=array([3, 5, 6, 7, 0, 0, 0, 0], dtype=int32)\n",
            "target_seq[0]=array([5, 6, 7, 0, 0, 0, 0, 0], dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = maxlength - 1\n",
        "def one_hot_encoder(sequence, batch_size, seq_len, vocab_size):\n",
        "  feature = np.zeros((batch_size, seq_len, vocab_size+1), dtype = np.float32)\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    for k in range(seq_len):\n",
        "      feature[i, k, sequence[i][k]] = 1\n",
        "\n",
        "  return feature"
      ],
      "metadata": {
        "id": "kpJL1UW7szrq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = len(docs)\n",
        "input_seq = one_hot_encoder(input_seq, batch_size, seq_len, vocab_size)"
      ],
      "metadata": {
        "id": "0rnK_p3_t5nz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.from_numpy(input_seq)\n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "metadata": {
        "id": "op2wiJenzhfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b3273e-ebcc-481e-82f7-a68223d2d6d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-c3455b344852>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  target_seq = torch.Tensor(target_seq)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU not available, running on CPU...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sIjpCrzzuzR",
        "outputId": "105eedfe-65c5-409b-a0bb-112ec6fc41b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, running on CPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "\n",
        "    out = out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, hidden\n",
        "\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "qYdksuRj0Viy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size = vocab_size+1, output_size = vocab_size+1, hidden_dim = 8, n_layers = 1)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "vzzRi4Pz3D2_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 7000\n",
        "lr = 0.0001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "q38pSa0K3xZx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = input_seq.to(device)\n",
        "print(f\"{input_seq.shape=}\")\n",
        "for epoch in range(1, n_epochs+1):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  out, hidden = model(input_seq)\n",
        "  out.to(device)\n",
        "  target_seq.to(device)\n",
        "  loss = criterion(out, target_seq.view(-1).long())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%50  == 0:\n",
        "    print('Epoch: {}/{}......'.format(epoch, n_epochs), end=' ')\n",
        "    print(\"Loss : {:.4f}\".format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpI2O_4E4HBh",
        "outputId": "55b05425-0a6d-48ed-cced-5fdc8b816ed7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_seq.shape=torch.Size([9, 8, 37])\n",
            "Epoch: 50/7000...... Loss : 3.5674\n",
            "Epoch: 100/7000...... Loss : 3.5278\n",
            "Epoch: 150/7000...... Loss : 3.4836\n",
            "Epoch: 200/7000...... Loss : 3.4345\n",
            "Epoch: 250/7000...... Loss : 3.3807\n",
            "Epoch: 300/7000...... Loss : 3.3225\n",
            "Epoch: 350/7000...... Loss : 3.2608\n",
            "Epoch: 400/7000...... Loss : 3.1965\n",
            "Epoch: 450/7000...... Loss : 3.1306\n",
            "Epoch: 500/7000...... Loss : 3.0642\n",
            "Epoch: 550/7000...... Loss : 2.9981\n",
            "Epoch: 600/7000...... Loss : 2.9332\n",
            "Epoch: 650/7000...... Loss : 2.8701\n",
            "Epoch: 700/7000...... Loss : 2.8095\n",
            "Epoch: 750/7000...... Loss : 2.7515\n",
            "Epoch: 800/7000...... Loss : 2.6966\n",
            "Epoch: 850/7000...... Loss : 2.6449\n",
            "Epoch: 900/7000...... Loss : 2.5963\n",
            "Epoch: 950/7000...... Loss : 2.5508\n",
            "Epoch: 1000/7000...... Loss : 2.5083\n",
            "Epoch: 1050/7000...... Loss : 2.4686\n",
            "Epoch: 1100/7000...... Loss : 2.4315\n",
            "Epoch: 1150/7000...... Loss : 2.3969\n",
            "Epoch: 1200/7000...... Loss : 2.3644\n",
            "Epoch: 1250/7000...... Loss : 2.3339\n",
            "Epoch: 1300/7000...... Loss : 2.3051\n",
            "Epoch: 1350/7000...... Loss : 2.2777\n",
            "Epoch: 1400/7000...... Loss : 2.2515\n",
            "Epoch: 1450/7000...... Loss : 2.2262\n",
            "Epoch: 1500/7000...... Loss : 2.2016\n",
            "Epoch: 1550/7000...... Loss : 2.1774\n",
            "Epoch: 1600/7000...... Loss : 2.1534\n",
            "Epoch: 1650/7000...... Loss : 2.1292\n",
            "Epoch: 1700/7000...... Loss : 2.1046\n",
            "Epoch: 1750/7000...... Loss : 2.0787\n",
            "Epoch: 1800/7000...... Loss : 2.0500\n",
            "Epoch: 1850/7000...... Loss : 2.0193\n",
            "Epoch: 1900/7000...... Loss : 1.9943\n",
            "Epoch: 1950/7000...... Loss : 1.9713\n",
            "Epoch: 2000/7000...... Loss : 1.9494\n",
            "Epoch: 2050/7000...... Loss : 1.9282\n",
            "Epoch: 2100/7000...... Loss : 1.9076\n",
            "Epoch: 2150/7000...... Loss : 1.8874\n",
            "Epoch: 2200/7000...... Loss : 1.8674\n",
            "Epoch: 2250/7000...... Loss : 1.8476\n",
            "Epoch: 2300/7000...... Loss : 1.8281\n",
            "Epoch: 2350/7000...... Loss : 1.8088\n",
            "Epoch: 2400/7000...... Loss : 1.7897\n",
            "Epoch: 2450/7000...... Loss : 1.7708\n",
            "Epoch: 2500/7000...... Loss : 1.7521\n",
            "Epoch: 2550/7000...... Loss : 1.7336\n",
            "Epoch: 2600/7000...... Loss : 1.7152\n",
            "Epoch: 2650/7000...... Loss : 1.6970\n",
            "Epoch: 2700/7000...... Loss : 1.6790\n",
            "Epoch: 2750/7000...... Loss : 1.6611\n",
            "Epoch: 2800/7000...... Loss : 1.6435\n",
            "Epoch: 2850/7000...... Loss : 1.6260\n",
            "Epoch: 2900/7000...... Loss : 1.6087\n",
            "Epoch: 2950/7000...... Loss : 1.5915\n",
            "Epoch: 3000/7000...... Loss : 1.5745\n",
            "Epoch: 3050/7000...... Loss : 1.5577\n",
            "Epoch: 3100/7000...... Loss : 1.5411\n",
            "Epoch: 3150/7000...... Loss : 1.5247\n",
            "Epoch: 3200/7000...... Loss : 1.5086\n",
            "Epoch: 3250/7000...... Loss : 1.4928\n",
            "Epoch: 3300/7000...... Loss : 1.4771\n",
            "Epoch: 3350/7000...... Loss : 1.4616\n",
            "Epoch: 3400/7000...... Loss : 1.4462\n",
            "Epoch: 3450/7000...... Loss : 1.4310\n",
            "Epoch: 3500/7000...... Loss : 1.4159\n",
            "Epoch: 3550/7000...... Loss : 1.4008\n",
            "Epoch: 3600/7000...... Loss : 1.3859\n",
            "Epoch: 3650/7000...... Loss : 1.3710\n",
            "Epoch: 3700/7000...... Loss : 1.3562\n",
            "Epoch: 3750/7000...... Loss : 1.3415\n",
            "Epoch: 3800/7000...... Loss : 1.3269\n",
            "Epoch: 3850/7000...... Loss : 1.3124\n",
            "Epoch: 3900/7000...... Loss : 1.2979\n",
            "Epoch: 3950/7000...... Loss : 1.2835\n",
            "Epoch: 4000/7000...... Loss : 1.2692\n",
            "Epoch: 4050/7000...... Loss : 1.2549\n",
            "Epoch: 4100/7000...... Loss : 1.2407\n",
            "Epoch: 4150/7000...... Loss : 1.2267\n",
            "Epoch: 4200/7000...... Loss : 1.2127\n",
            "Epoch: 4250/7000...... Loss : 1.1988\n",
            "Epoch: 4300/7000...... Loss : 1.1850\n",
            "Epoch: 4350/7000...... Loss : 1.1713\n",
            "Epoch: 4400/7000...... Loss : 1.1577\n",
            "Epoch: 4450/7000...... Loss : 1.1442\n",
            "Epoch: 4500/7000...... Loss : 1.1308\n",
            "Epoch: 4550/7000...... Loss : 1.1175\n",
            "Epoch: 4600/7000...... Loss : 1.1043\n",
            "Epoch: 4650/7000...... Loss : 1.0912\n",
            "Epoch: 4700/7000...... Loss : 1.0782\n",
            "Epoch: 4750/7000...... Loss : 1.0653\n",
            "Epoch: 4800/7000...... Loss : 1.0525\n",
            "Epoch: 4850/7000...... Loss : 1.0398\n",
            "Epoch: 4900/7000...... Loss : 1.0273\n",
            "Epoch: 4950/7000...... Loss : 1.0148\n",
            "Epoch: 5000/7000...... Loss : 1.0024\n",
            "Epoch: 5050/7000...... Loss : 0.9902\n",
            "Epoch: 5100/7000...... Loss : 0.9781\n",
            "Epoch: 5150/7000...... Loss : 0.9660\n",
            "Epoch: 5200/7000...... Loss : 0.9541\n",
            "Epoch: 5250/7000...... Loss : 0.9423\n",
            "Epoch: 5300/7000...... Loss : 0.9306\n",
            "Epoch: 5350/7000...... Loss : 0.9190\n",
            "Epoch: 5400/7000...... Loss : 0.9075\n",
            "Epoch: 5450/7000...... Loss : 0.8962\n",
            "Epoch: 5500/7000...... Loss : 0.8849\n",
            "Epoch: 5550/7000...... Loss : 0.8738\n",
            "Epoch: 5600/7000...... Loss : 0.8628\n",
            "Epoch: 5650/7000...... Loss : 0.8519\n",
            "Epoch: 5700/7000...... Loss : 0.8411\n",
            "Epoch: 5750/7000...... Loss : 0.8304\n",
            "Epoch: 5800/7000...... Loss : 0.8199\n",
            "Epoch: 5850/7000...... Loss : 0.8094\n",
            "Epoch: 5900/7000...... Loss : 0.7991\n",
            "Epoch: 5950/7000...... Loss : 0.7889\n",
            "Epoch: 6000/7000...... Loss : 0.7789\n",
            "Epoch: 6050/7000...... Loss : 0.7689\n",
            "Epoch: 6100/7000...... Loss : 0.7591\n",
            "Epoch: 6150/7000...... Loss : 0.7494\n",
            "Epoch: 6200/7000...... Loss : 0.7398\n",
            "Epoch: 6250/7000...... Loss : 0.7303\n",
            "Epoch: 6300/7000...... Loss : 0.7209\n",
            "Epoch: 6350/7000...... Loss : 0.7116\n",
            "Epoch: 6400/7000...... Loss : 0.7025\n",
            "Epoch: 6450/7000...... Loss : 0.6935\n",
            "Epoch: 6500/7000...... Loss : 0.6845\n",
            "Epoch: 6550/7000...... Loss : 0.6757\n",
            "Epoch: 6600/7000...... Loss : 0.6670\n",
            "Epoch: 6650/7000...... Loss : 0.6584\n",
            "Epoch: 6700/7000...... Loss : 0.6499\n",
            "Epoch: 6750/7000...... Loss : 0.6415\n",
            "Epoch: 6800/7000...... Loss : 0.6332\n",
            "Epoch: 6850/7000...... Loss : 0.6251\n",
            "Epoch: 6900/7000...... Loss : 0.6170\n",
            "Epoch: 6950/7000...... Loss : 0.6090\n",
            "Epoch: 7000/7000...... Loss : 0.6011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, words):\n",
        "  sentence = np.array([[word2int[word] for word in words]])\n",
        "  sentence = one_hot_encoder(sentence, 1, sentence.shape[1], vocab_size)\n",
        "  sentence = torch.from_numpy(sentence)\n",
        "  sentence = sentence.to(device)\n",
        "\n",
        "  out, hidden = model(sentence)\n",
        "\n",
        "  prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "  word_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "  return int2word[word_ind+1], hidden"
      ],
      "metadata": {
        "id": "R1Wrblx7HmYr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, out_size, start = \"hey\"):\n",
        "  model.eval()\n",
        "\n",
        "  start = start.lower()\n",
        "\n",
        "  start = start.split()\n",
        "\n",
        "  words = [word for word in start]\n",
        "\n",
        "  size = out_size - len(words)\n",
        "\n",
        "  print(\"===============\",size)\n",
        "  for i in range(size):\n",
        "    o, h = predict(model, words)\n",
        "    words.append(o)\n",
        "\n",
        "  return \" \".join(words)"
      ],
      "metadata": {
        "id": "93FD5LukJ9j4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample(model, 7, \"charles\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wQr4U7xfLZ7y",
        "outputId": "813049bd-96c6-41d5-e49f-c02f2012e193"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'charles will f1 is is is is'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1imo2U5W9AzAqjxvNIqe2GhlEx23VLftA",
      "authorship_tag": "ABX9TyM19UCHhkVR6sUF+1ZNloC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}